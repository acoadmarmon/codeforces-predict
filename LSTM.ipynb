{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)\n",
    "# load the dataset but only keep the top n words, zero the rest\n",
    "top_words = 5000\n",
    "max_review_length = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                         math\n",
      "1               implementation\n",
      "2                         math\n",
      "3                     geometry\n",
      "4                         math\n",
      "5               implementation\n",
      "6                           dp\n",
      "7               implementation\n",
      "8                 numbertheory\n",
      "9                           dp\n",
      "10      constructivealgorithms\n",
      "11              specialproblem\n",
      "12              implementation\n",
      "13              specialproblem\n",
      "14              implementation\n",
      "15              specialproblem\n",
      "16              implementation\n",
      "17              specialproblem\n",
      "18                     strings\n",
      "19              specialproblem\n",
      "20                        math\n",
      "21              specialproblem\n",
      "22              implementation\n",
      "23              specialproblem\n",
      "24              datastructures\n",
      "25              implementation\n",
      "26              specialproblem\n",
      "27               dfsandsimilar\n",
      "28              implementation\n",
      "29              specialproblem\n",
      "                 ...          \n",
      "7974                bruteforce\n",
      "7975            implementation\n",
      "7976    constructivealgorithms\n",
      "7977          divideandconquer\n",
      "7978              binarysearch\n",
      "7979                    graphs\n",
      "7980                      math\n",
      "7981             shortestpaths\n",
      "7982                  bitmasks\n",
      "7983                bruteforce\n",
      "7984            implementation\n",
      "7985             dfsandsimilar\n",
      "7986                       dsu\n",
      "7987                    graphs\n",
      "7988                     trees\n",
      "7989                bruteforce\n",
      "7990            implementation\n",
      "7991            implementation\n",
      "7992             probabilities\n",
      "7993                     trees\n",
      "7994                  geometry\n",
      "7995             ternarysearch\n",
      "7996    constructivealgorithms\n",
      "7997                        dp\n",
      "7998                     games\n",
      "7999                      math\n",
      "8000             probabilities\n",
      "8001                   strings\n",
      "8002            implementation\n",
      "8003                  sortings\n",
      "Name: tag, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "import collections\n",
    "df = pandas.read_csv('words_all.csv')\n",
    "print(df['tag'])\n",
    "allWords = df['main_text'].str.cat(sep=' ').split(' ')\n",
    "allTags = list(set(df['tag'].str.cat(sep=' ').split(' ')))\n",
    "\n",
    "def build_dataset(words):\n",
    "    count = collections.Counter(words).most_common()\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    return dictionary, reverse_dictionary\n",
    "\n",
    "vocabularyF, vocabularyR = build_dataset(allWords)\n",
    "vocab_size = len(vocabularyF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11, 27, 11, ..., 26,  8,  0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = df['main_text'].as_matrix()\n",
    "data = [[vocabularyF[i] for i in j.split(' ')] for j in text]\n",
    "labels = [allTags.index(i) for i in df['tag'].as_matrix() if i != ' tag']\n",
    "train_data = data[:6403]\n",
    "y_train = np.asarray(labels[:6403])\n",
    "test_data = data[6403:]\n",
    "y_test = np.asarray(labels[6403:])\n",
    "max_review_length = 500\n",
    "X_train = sequence.pad_sequences(train_data, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(test_data, maxlen=max_review_length)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 500, 32)           590048    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 643,349\n",
      "Trainable params: 643,349\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drewmarmon\\Anaconda3\\lib\\site-packages\\keras\\models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "6403/6403 [==============================] - 27s 4ms/step - loss: 384.1294 - acc: 0.0103\n",
      "Epoch 2/3\n",
      "6403/6403 [==============================] - 26s 4ms/step - loss: 382.2923 - acc: 0.0100\n",
      "Epoch 3/3\n",
      "6403/6403 [==============================] - 27s 4ms/step - loss: 382.2922 - acc: 0.0100\n",
      "Accuracy: 0.87%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, nb_epoch=3, batch_size=64)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
